<<<<<<< HEAD
from nubem_core.memoria.memoria_proyecto import (
    cargar_memoria,
    actualizar_memoria,
    aÃ±adir_a_lista
)

from nubem_core.logger import log_event

def mostrar_contexto_actual():
    memoria = cargar_memoria()
    print("ðŸ“Œ Contexto actual del proyecto:")
=======
import os
import requests

# Detectar si se debe usar Firestore o memoria local
USE_FIRESTORE = os.getenv("NUBEMFLOW_MODE", "local") == "cloud"

if USE_FIRESTORE:
    from nubem_core.memoria.memoria_firestore import (
        cargar_memoria,
        actualizar_memoria,
        aÃ±adir_a_lista
    )
else:
    from nubem_core.memoria.memoria_proyecto import (
        cargar_memoria,
        actualizar_memoria,
        aÃ±adir_a_lista
    )

# ðŸ” Flujo GPT
def mostrar_contexto_actual(proyecto="HTX"):
    memoria = cargar_memoria(proyecto) if USE_FIRESTORE else cargar_memoria()
    print("ðŸ“Œ Contexto actual:")
>>>>>>> 067fa14be1ddbc0bc8296688c42b14c8a9f386c8
    for k, v in memoria.items():
        if isinstance(v, list):
            print(f"- {k.replace('_', ' ').capitalize()}:")
            for item in v:
                print(f"   â€¢ {item}")
        else:
            print(f"- {k.replace('_', ' ').capitalize()}: {v}")

<<<<<<< HEAD
def actualizar_contexto(proyecto=None, pm=None, objetivo=None):
    if proyecto:
        actualizar_memoria("proyecto", proyecto)
    if pm:
        actualizar_memoria("pm", pm)
    if objetivo:
        actualizar_memoria("objetivo", objetivo)
    log_event("info", "gpt_memoria", "Contexto actualizado manualmente")

def sugerir_accion_encadenada(tarea_detectada):
    print(f"ðŸ¤– GPT sugiere: Â¿Quieres imputar horas para '{tarea_detectada}'?")
    respuesta = input("âž¡ï¸ [sÃ­ / no]: ").strip().lower()
    if respuesta == "sÃ­":
        print("â± AcciÃ³n: redirigiendo a imputaciÃ³n horaria...")
        from add_worklog_JIRA import imputar_horas
        imputar_horas("HTX-XXX", "712020:tecnico01", 2, f"Tarea: {tarea_detectada}")
    else:
        print("ðŸ§¾ Ok. La tarea serÃ¡ registrada como crÃ­tica.")
        aÃ±adir_a_lista("tareas_criticas", tarea_detectada)

if __name__ == "__main__":
    mostrar_contexto_actual()
    print("
ðŸ”„ SimulaciÃ³n de tarea detectada por GPT:")
    sugerir_accion_encadenada("Revisar cableado de planta 2")
=======
def sugerir_imputacion_para_tarea(tarea_detectada, proyecto="HTX"):
    print(f"ðŸ¤– GPT detectÃ³ la tarea: '{tarea_detectada}'")
    respuesta = input("âž¡ï¸ Â¿Deseas imputar horas por esta tarea? [sÃ­ / no]: ").strip().lower()

    if respuesta != "sÃ­":
        aÃ±adir_a_lista(proyecto, "tareas_criticas", tarea_detectada) if USE_FIRESTORE else aÃ±adir_a_lista("tareas_criticas", tarea_detectada)
        print("ðŸ“ Tarea registrada como crÃ­tica.")
        return

    issue_key = input("ðŸ”‘ Clave del issue JIRA (ej: HTX-123): ").strip().upper()
    horas = float(input("â± Â¿CuÃ¡ntas horas deseas imputar?: ").strip())
    comentario = input("ðŸ—’ Comentario tÃ©cnico (opcional): ").strip()

    url = "https://europe-west1-hoteltech-gmail-api.cloudfunctions.net/imputar_horas_jira"
    payload = {
        "issue_key": issue_key,
        "horas": horas,
        "comentario": comentario
    }

    print("ðŸ“¡ Enviando imputaciÃ³n...")
    response = requests.post(url, json=payload)

    if response.status_code == 200:
        print("âœ… Horas imputadas correctamente en JIRA.")
    else:
        print("âŒ Error al imputar horas:", response.text)

# EjecuciÃ³n manual
if __name__ == "__main__":
    proyecto = "HTX"
    mostrar_contexto_actual(proyecto)
    sugerir_imputacion_para_tarea("Actualizar topologÃ­a de red planta 2", proyecto)
>>>>>>> 067fa14be1ddbc0bc8296688c42b14c8a9f386c8
